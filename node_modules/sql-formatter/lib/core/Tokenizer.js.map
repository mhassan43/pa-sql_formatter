{"version":3,"sources":["../../src/core/Tokenizer.ts"],"names":["WHITESPACE_REGEX","NULL_REGEX","toCanonicalKeyword","text","toUpperCase","Tokenizer","cfg","tokens","preprocess","quotedIdentRegex","regexFactory","createQuoteRegex","identTypes","REGEX_MAP","TokenType","IDENT","createIdentRegex","identChars","STRING","stringTypes","VARIABLE","variableTypes","createVariableRegex","RESERVED_KEYWORD","createReservedWordRegex","reservedKeywords","RESERVED_DEPENDENT_CLAUSE","reservedDependentClauses","RESERVED_LOGICAL_OPERATOR","reservedLogicalOperators","RESERVED_COMMAND","reservedCommands","RESERVED_BINARY_COMMAND","reservedBinaryCommands","RESERVED_JOIN_CONDITION","reservedJoinConditions","OPERATOR","createOperatorRegex","operators","BLOCK_START","createParenRegex","blockStart","BLOCK_END","blockEnd","RESERVED_CASE_START","RESERVED_CASE_END","LINE_COMMENT","createLineCommentRegex","lineCommentTypes","BLOCK_COMMENT","NUMBER","PARAMETER","EOF","paramPatterns","excludePatternsWithoutRegexes","regex","createParameterRegex","namedParamTypes","createIdentPattern","paramChars","parseKey","v","slice","quotedParamTypes","createQuotePattern","getEscapedPlaceholderKey","key","quoteChar","numberedParamTypes","positionalParams","undefined","patterns","filter","p","input","index","token","length","whitespaceBefore","getWhitespace","getNextToken","Error","push","lastIndex","matches","match","previousToken","matchToken","matchQuotedIdentToken","matchPlaceholderToken","matchReservedWordToken","type","transform","id","value","replace","RegExp","matchReservedToken","tokenType"],"mappings":";;;;;;;;;AAAA;;AAEA;;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,IAAMA,gBAAgB,wGAAtB;AACA,IAAMC,UAAU,0BAAhB,C,CAA6B;;AAE7B,IAAMC,kBAAkB,GAAG,SAArBA,kBAAqB,CAACC,IAAD;AAAA,SAAkB,+BAAmBA,IAAI,CAACC,WAAL,EAAnB,CAAlB;AAAA,CAA3B;AAEA;;;AAuDA;IACqBC,S;AAInB;AAEA;AAKA,qBAAYC,GAAZ,EAAmC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;;AAAA;;AAAA;;AAAA,mCANnB,EAMmB;;AAAA,mCAJnB,CAImB;;AAAA,wCAFd,UAACC,MAAD;AAAA,aAAqBA,MAArB;AAAA,KAEc;;AACjC,QAAID,GAAG,CAACE,UAAR,EAAoB;AAClB,WAAKA,UAAL,GAAkBF,GAAG,CAACE,UAAtB;AACD;;AAED,SAAKC,gBAAL,GAAwBC,YAAY,CAACC,gBAAb,CAA8BL,GAAG,CAACM,UAAlC,CAAxB;AAEA,SAAKC,SAAL,2DACGC,iBAAUC,KADb,EACqBL,YAAY,CAACM,gBAAb,CAA8BV,GAAG,CAACW,UAAlC,CADrB,oCAEGH,iBAAUI,MAFb,EAEsBR,YAAY,CAACC,gBAAb,CAA8BL,GAAG,CAACa,WAAlC,CAFtB,oCAGGL,iBAAUM,QAHb,EAGwBd,GAAG,CAACe,aAAJ,GAClBX,YAAY,CAACY,mBAAb,CAAiChB,GAAG,CAACe,aAArC,CADkB,GAElBpB,UALN,oCAMGa,iBAAUS,gBANb,EAMgCb,YAAY,CAACc,uBAAb,CAC5BlB,GAAG,CAACmB,gBADwB,EAE5BnB,GAAG,CAACW,UAFwB,CANhC,oCAUGH,iBAAUY,yBAVb,EAUyChB,YAAY,CAACc,uBAAb,0BACrClB,GAAG,CAACqB,wBADiC,yEACL,EADK,EAErCrB,GAAG,CAACW,UAFiC,CAVzC,oCAcGH,iBAAUc,yBAdb,EAcyClB,YAAY,CAACc,uBAAb,0BACrClB,GAAG,CAACuB,wBADiC,yEACL,CAAC,KAAD,EAAQ,IAAR,CADK,EAErCvB,GAAG,CAACW,UAFiC,CAdzC,oCAkBGH,iBAAUgB,gBAlBb,EAkBgCpB,YAAY,CAACc,uBAAb,CAC5BlB,GAAG,CAACyB,gBADwB,EAE5BzB,GAAG,CAACW,UAFwB,CAlBhC,oCAsBGH,iBAAUkB,uBAtBb,EAsBuCtB,YAAY,CAACc,uBAAb,CACnClB,GAAG,CAAC2B,sBAD+B,EAEnC3B,GAAG,CAACW,UAF+B,CAtBvC,oCA0BGH,iBAAUoB,uBA1Bb,EA0BuCxB,YAAY,CAACc,uBAAb,0BACnClB,GAAG,CAAC6B,sBAD+B,yEACL,CAAC,IAAD,EAAO,OAAP,CADK,EAEnC7B,GAAG,CAACW,UAF+B,CA1BvC,oCA8BGH,iBAAUsB,QA9Bb,EA8BwB1B,YAAY,CAAC2B,mBAAb,CAAiC,wBAAjC,GACpB,IADoB,EAEpB,IAFoB,EAGpB,IAHoB,EAIpB,IAJoB,8CAKhB/B,GAAG,CAACgC,SALY,2DAKC,EALD,GA9BxB,oCAqCGxB,iBAAUyB,WArCb,EAqC2B7B,YAAY,CAAC8B,gBAAb,oBAA8BlC,GAAG,CAACmC,UAAlC,6DAAgD,CAAC,GAAD,CAAhD,CArC3B,oCAsCG3B,iBAAU4B,SAtCb,EAsCyBhC,YAAY,CAAC8B,gBAAb,kBAA8BlC,GAAG,CAACqC,QAAlC,yDAA8C,CAAC,GAAD,CAA9C,CAtCzB,oCAuCG7B,iBAAU8B,mBAvCb,4EAwCG9B,iBAAU+B,iBAxCb,kEAyCG/B,iBAAUgC,YAzCb,EAyC4BpC,YAAY,CAACqC,sBAAb,0BAAoCzC,GAAG,CAAC0C,gBAAxC,yEAA4D,CAAC,IAAD,CAA5D,CAzC5B,oCA0CGlC,iBAAUmC,aA1Cb,iGA2CGnC,iBAAUoC,MA3Cb,gOA6CGpC,iBAAUqC,SA7Cb,EA6CyBlD,UA7CzB,oCA8CGa,iBAAUsC,GA9Cb,EA8CmBnD,UA9CnB;AAiDA,SAAKoD,aAAL,GAAqB,KAAKC,6BAAL,CAAmC,CACtD;AACE;AACAC,MAAAA,KAAK,EAAE7C,YAAY,CAAC8C,oBAAb,yBACLlD,GAAG,CAACmD,eADC,uEACkB,EADlB,EAEL/C,YAAY,CAACgD,kBAAb,CAAgCpD,GAAG,CAACqD,UAAJ,IAAkBrD,GAAG,CAACW,UAAtD,CAFK,CAFT;AAME2C,MAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,eAAIA,CAAC,CAACC,KAAF,CAAQ,CAAR,CAAJ;AAAA;AANb,KADsD,EAStD;AACE;AACAP,MAAAA,KAAK,EAAE7C,YAAY,CAAC8C,oBAAb,0BACLlD,GAAG,CAACyD,gBADC,yEACmB,EADnB,EAELrD,YAAY,CAACsD,kBAAb,CAAgC1D,GAAG,CAACM,UAApC,CAFK,CAFT;AAMEgD,MAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,eACT,KAAI,CAACI,wBAAL,CAA8B;AAAEC,UAAAA,GAAG,EAAEL,CAAC,CAACC,KAAF,CAAQ,CAAR,EAAW,CAAC,CAAZ,CAAP;AAAuBK,UAAAA,SAAS,EAAEN,CAAC,CAACC,KAAF,CAAQ,CAAC,CAAT;AAAlC,SAA9B,CADS;AAAA;AANb,KATsD,EAkBtD;AACE;AACAP,MAAAA,KAAK,EAAE7C,YAAY,CAAC8C,oBAAb,0BAAkClD,GAAG,CAAC8D,kBAAtC,yEAA4D,EAA5D,EAAgE,QAAhE,CAFT;AAGER,MAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,eAAIA,CAAC,CAACC,KAAF,CAAQ,CAAR,CAAJ;AAAA;AAHb,KAlBsD,EAuBtD;AACE;AACAP,MAAAA,KAAK,EAAEjD,GAAG,CAAC+D,gBAAJ,8BAAkCC,SAF3C;AAGEV,MAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,eAAIA,CAAC,CAACC,KAAF,CAAQ,CAAR,CAAJ;AAAA;AAHb,KAvBsD,CAAnC,CAArB;AA6BD;;;;WAED,uCACES,QADF,EAEE;AACA,aAAOA,QAAQ,CAACC,MAAT,CAAgB,UAACC,CAAD;AAAA,eAA0BA,CAAC,CAAClB,KAAF,KAAYe,SAAtC;AAAA,OAAhB,CAAP;AACD;AAED;AACF;AACA;AACA;AACA;AACA;AACA;;;;WACE,kBAAgBI,KAAhB,EAAwC;AACtC,WAAKA,KAAL,GAAaA,KAAb;AACA,WAAKC,KAAL,GAAa,CAAb;AACA,UAAMpE,MAAe,GAAG,EAAxB;AACA,UAAIqE,KAAJ,CAJsC,CAMtC;;AACA,aAAO,KAAKD,KAAL,GAAa,KAAKD,KAAL,CAAWG,MAA/B,EAAuC;AACrC;AACA,YAAMC,gBAAgB,GAAG,KAAKC,aAAL,EAAzB;;AAEA,YAAI,KAAKJ,KAAL,GAAa,KAAKD,KAAL,CAAWG,MAA5B,EAAoC;AAClC;AACAD,UAAAA,KAAK,GAAG,KAAKI,YAAL,CAAkBJ,KAAlB,CAAR;;AACA,cAAI,CAACA,KAAL,EAAY;AACV,kBAAM,IAAIK,KAAJ,qCAAsCP,KAAK,CAACZ,KAAN,CAAY,KAAKa,KAAjB,EAAwB,GAAxB,CAAtC,QAAN;AACD;;AAEDpE,UAAAA,MAAM,CAAC2E,IAAP,iCAAiBN,KAAjB;AAAwBE,YAAAA,gBAAgB,EAAhBA;AAAxB;AACD;AACF;;AACD,aAAO,KAAKtE,UAAL,CAAgBD,MAAhB,CAAP;AACD;;;WAED,yBAAgC;AAC9BP,MAAAA,gBAAgB,CAACmF,SAAjB,GAA6B,KAAKR,KAAlC;AACA,UAAMS,OAAO,GAAG,KAAKV,KAAL,CAAWW,KAAX,CAAiBrF,gBAAjB,CAAhB;;AACA,UAAIoF,OAAJ,EAAa;AACX;AACA,aAAKT,KAAL,IAAcS,OAAO,CAAC,CAAD,CAAP,CAAWP,MAAzB;AACA,eAAOO,OAAO,CAAC,CAAD,CAAd;AACD,OAJD,MAIO;AACL,eAAO,EAAP;AACD;AACF;;;WAED,sBAAqBE,aAArB,EAA+D;AAC7D,aACE,KAAKC,UAAL,CAAgBzE,iBAAUgC,YAA1B,KACA,KAAKyC,UAAL,CAAgBzE,iBAAUmC,aAA1B,CADA,IAEA,KAAKsC,UAAL,CAAgBzE,iBAAUI,MAA1B,CAFA,IAGA,KAAKsE,qBAAL,EAHA,IAIA,KAAKD,UAAL,CAAgBzE,iBAAUM,QAA1B,CAJA,IAKA,KAAKmE,UAAL,CAAgBzE,iBAAUyB,WAA1B,CALA,IAMA,KAAKgD,UAAL,CAAgBzE,iBAAU4B,SAA1B,CANA,IAOA,KAAK+C,qBAAL,EAPA,IAQA,KAAKF,UAAL,CAAgBzE,iBAAUoC,MAA1B,CARA,IASA,KAAKwC,sBAAL,CAA4BJ,aAA5B,CATA,IAUA,KAAKC,UAAL,CAAgBzE,iBAAUC,KAA1B,CAVA,IAWA,KAAKwE,UAAL,CAAgBzE,iBAAUsB,QAA1B,CAZF;AAcD;;;WAED,iCAAmD;AAAA,iDACf,KAAKiB,aADU;AAAA;;AAAA;AACjD,4DAAsD;AAAA;AAAA,cAAzCE,KAAyC,eAAzCA,KAAyC;AAAA,cAAlCK,QAAkC,eAAlCA,QAAkC;AACpD,cAAMgB,KAAK,GAAG,KAAKS,KAAL,CAAW;AACvB9B,YAAAA,KAAK,EAALA,KADuB;AAEvBoC,YAAAA,IAAI,EAAE7E,iBAAUqC,SAFO;AAGvByC,YAAAA,SAAS,EAAEC;AAHY,WAAX,CAAd;;AAKA,cAAIjB,KAAJ,EAAW;AACT,mDAAYA,KAAZ;AAAmBV,cAAAA,GAAG,EAAEN,QAAQ,CAACgB,KAAK,CAACkB,KAAP;AAAhC;AACD;AACF;AAVgD;AAAA;AAAA;AAAA;AAAA;;AAWjD,aAAOxB,SAAP;AACD;;;WAED,wCAAiG;AAAA,UAA9DJ,GAA8D,QAA9DA,GAA8D;AAAA,UAAzDC,SAAyD,QAAzDA,SAAyD;AAC/F,aAAOD,GAAG,CAAC6B,OAAJ,CAAY,IAAIC,MAAJ,CAAW,yBAAa,OAAO7B,SAApB,CAAX,EAA2C,IAA3C,CAAZ,EAA8DA,SAA9D,CAAP;AACD;;;WAED,iCAAmD;AACjD,aAAO,KAAKkB,KAAL,CAAW;AAChB9B,QAAAA,KAAK,EAAE,KAAK9C,gBADI;AAEhBkF,QAAAA,IAAI,EAAE7E,iBAAUC,KAFA;AAGhB6E,QAAAA,SAAS,EAAEC;AAHK,OAAX,CAAP;AAKD;;;WAED,gCAA+BP,aAA/B,EAAyE;AACvE;AACA;AACA,UAAI,CAAAA,aAAa,SAAb,IAAAA,aAAa,WAAb,YAAAA,aAAa,CAAEQ,KAAf,MAAyB,GAA7B,EAAkC;AAChC,eAAOxB,SAAP;AACD,OALsE,CAOvE;;;AACA,aACE,KAAK2B,kBAAL,CAAwBnF,iBAAU8B,mBAAlC,KACA,KAAKqD,kBAAL,CAAwBnF,iBAAU+B,iBAAlC,CADA,IAEA,KAAKoD,kBAAL,CAAwBnF,iBAAUgB,gBAAlC,CAFA,IAGA,KAAKmE,kBAAL,CAAwBnF,iBAAUkB,uBAAlC,CAHA,IAIA,KAAKiE,kBAAL,CAAwBnF,iBAAUY,yBAAlC,CAJA,IAKA,KAAKuE,kBAAL,CAAwBnF,iBAAUc,yBAAlC,CALA,IAMA,KAAKqE,kBAAL,CAAwBnF,iBAAUS,gBAAlC,CANA,IAOA,KAAK0E,kBAAL,CAAwBnF,iBAAUoB,uBAAlC,CARF;AAUD,K,CAED;;;;WACA,4BAA2BgE,SAA3B,EAAoE;AAClE,aAAO,KAAKb,KAAL,CAAW;AAChBM,QAAAA,IAAI,EAAEO,SADU;AAEhB3C,QAAAA,KAAK,EAAE,KAAK1C,SAAL,CAAeqF,SAAf,CAFS;AAGhBN,QAAAA,SAAS,EAAE1F;AAHK,OAAX,CAAP;AAKD,K,CAED;;;;WACA,oBAAmBgG,SAAnB,EAA4D;AAC1D,aAAO,KAAKb,KAAL,CAAW;AAChBM,QAAAA,IAAI,EAAEO,SADU;AAEhB3C,QAAAA,KAAK,EAAE,KAAK1C,SAAL,CAAeqF,SAAf,CAFS;AAGhBN,QAAAA,SAAS,EAAEC;AAHK,OAAX,CAAP;AAKD,K,CAED;;;;WACA,sBAQsB;AAAA,UAPpBF,IAOoB,SAPpBA,IAOoB;AAAA,UANpBpC,KAMoB,SANpBA,KAMoB;AAAA,UALpBqC,SAKoB,SALpBA,SAKoB;AACpBrC,MAAAA,KAAK,CAAC4B,SAAN,GAAkB,KAAKR,KAAvB;AACA,UAAMS,OAAO,GAAG,KAAKV,KAAL,CAAWW,KAAX,CAAiB9B,KAAjB,CAAhB;;AACA,UAAI6B,OAAJ,EAAa;AACX;AACA,aAAKT,KAAL,IAAcS,OAAO,CAAC,CAAD,CAAP,CAAWP,MAAzB;AACA,eAAO;AACLc,UAAAA,IAAI,EAAJA,IADK;AAELxF,UAAAA,IAAI,EAAEiF,OAAO,CAAC,CAAD,CAFR;AAGLU,UAAAA,KAAK,EAAEF,SAAS,CAACR,OAAO,CAAC,CAAD,CAAR;AAHX,SAAP;AAKD;;AACD,aAAOd,SAAP;AACD","sourcesContent":["import { equalizeWhitespace, escapeRegExp, id } from 'src/utils';\n\nimport * as regexFactory from './regexFactory';\nimport { type Token, TokenType } from './token';\n\n// A note about regular expressions\n//\n// We're using a sticky flag \"y\" in all tokenizing regexes.\n// This works a bit like ^, anchoring the regex to the start,\n// but when ^ anchores the regex to the start of string (or line),\n// the sticky flag anchors it to search start position, which we\n// can change by setting RegExp.lastIndex.\n//\n// This allows us to avoid slicing off tokens from the start of input string\n// (which we used in the past) and just move the match start position forward,\n// which is much more performant on long strings.\n\nconst WHITESPACE_REGEX = /(\\s+)/uy;\nconst NULL_REGEX = /(?!)/uy; // zero-width negative lookahead, matches nothing\n\nconst toCanonicalKeyword = (text: string) => equalizeWhitespace(text.toUpperCase());\n\n/** Struct that defines how a SQL language can be broken into tokens */\ninterface TokenizerOptions {\n  // Main clauses that start new block, like: SELECT, FROM, WHERE, ORDER BY\n  reservedCommands: string[];\n  // Logical operator keywords, defaults to: [AND, OR]\n  reservedLogicalOperators?: string[];\n  // Keywords in CASE expressions that begin new line, like: WHEN, ELSE\n  reservedDependentClauses: string[];\n  // Keywords that create newline but no indentaion of their body.\n  // These contain set operations like UNION and various joins like LEFT OUTER JOIN\n  reservedBinaryCommands: string[];\n  // keywords used for JOIN conditions, defaults to: [ON, USING]\n  reservedJoinConditions?: string[];\n  // all other reserved words (not included to any of the above lists)\n  reservedKeywords: string[];\n  // Types of quotes to use for strings\n  stringTypes: regexFactory.QuoteType[];\n  // Types of quotes to use for quoted identifiers\n  identTypes: regexFactory.QuoteType[];\n  // Types of quotes to use for variables\n  variableTypes?: regexFactory.VariableType[];\n  // Open-parenthesis characters, like: (, [, {\n  blockStart?: string[];\n  // Close-parenthesis characters, like: ), ], }\n  blockEnd?: string[];\n  // True to allow for positional \"?\" parameter placeholders\n  positionalParams?: boolean;\n  // Prefixes for numbered parameter placeholders to support, e.g. :1, :2, :3\n  numberedParamTypes?: ('?' | ':' | '$')[];\n  // Prefixes for named parameter placeholders to support, e.g. :name\n  namedParamTypes?: (':' | '@' | '$')[];\n  // Prefixes for quoted parameter placeholders to support, e.g. :\"name\"\n  // The type of quotes will depend on `identifierTypes` option.\n  quotedParamTypes?: (':' | '@' | '$')[];\n  // Line comment types to support, defaults to --\n  lineCommentTypes?: string[];\n  // Additional characters to support in identifiers\n  identChars?: regexFactory.IdentChars;\n  // Additional characters to support in named parameters\n  // Use this when parameters allow different characters from identifiers\n  // Defaults to `identChars`.\n  paramChars?: regexFactory.IdentChars;\n  // Additional multi-character operators to support, in addition to <=, >=, <>, !=\n  operators?: string[];\n  // Allows custom modifications on the token array.\n  // Called after the whole input string has been split into tokens.\n  // The result of this will be the output of the tokenizer.\n  preprocess?: (tokens: Token[]) => Token[];\n}\n\ninterface ParamPattern {\n  regex: RegExp;\n  parseKey: (s: string) => string;\n}\n\n/** Converts SQL language string into a token stream */\nexport default class Tokenizer {\n  private REGEX_MAP: Record<TokenType, RegExp>;\n  private quotedIdentRegex: RegExp;\n  private paramPatterns: ParamPattern[];\n  // The input SQL string to process\n  private input = '';\n  // Current position in string\n  private index = 0;\n\n  private preprocess = (tokens: Token[]) => tokens;\n\n  constructor(cfg: TokenizerOptions) {\n    if (cfg.preprocess) {\n      this.preprocess = cfg.preprocess;\n    }\n\n    this.quotedIdentRegex = regexFactory.createQuoteRegex(cfg.identTypes);\n\n    this.REGEX_MAP = {\n      [TokenType.IDENT]: regexFactory.createIdentRegex(cfg.identChars),\n      [TokenType.STRING]: regexFactory.createQuoteRegex(cfg.stringTypes),\n      [TokenType.VARIABLE]: cfg.variableTypes\n        ? regexFactory.createVariableRegex(cfg.variableTypes)\n        : NULL_REGEX,\n      [TokenType.RESERVED_KEYWORD]: regexFactory.createReservedWordRegex(\n        cfg.reservedKeywords,\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_DEPENDENT_CLAUSE]: regexFactory.createReservedWordRegex(\n        cfg.reservedDependentClauses ?? [],\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_LOGICAL_OPERATOR]: regexFactory.createReservedWordRegex(\n        cfg.reservedLogicalOperators ?? ['AND', 'OR'],\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_COMMAND]: regexFactory.createReservedWordRegex(\n        cfg.reservedCommands,\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_BINARY_COMMAND]: regexFactory.createReservedWordRegex(\n        cfg.reservedBinaryCommands,\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_JOIN_CONDITION]: regexFactory.createReservedWordRegex(\n        cfg.reservedJoinConditions ?? ['ON', 'USING'],\n        cfg.identChars\n      ),\n      [TokenType.OPERATOR]: regexFactory.createOperatorRegex('+-/*%&|^><=.,;[]{}`:$@', [\n        '<>',\n        '<=',\n        '>=',\n        '!=',\n        ...(cfg.operators ?? []),\n      ]),\n      [TokenType.BLOCK_START]: regexFactory.createParenRegex(cfg.blockStart ?? ['(']),\n      [TokenType.BLOCK_END]: regexFactory.createParenRegex(cfg.blockEnd ?? [')']),\n      [TokenType.RESERVED_CASE_START]: /(CASE)\\b/iuy,\n      [TokenType.RESERVED_CASE_END]: /(END)\\b/iuy,\n      [TokenType.LINE_COMMENT]: regexFactory.createLineCommentRegex(cfg.lineCommentTypes ?? ['--']),\n      [TokenType.BLOCK_COMMENT]: /(\\/\\*[^]*?(?:\\*\\/|$))/uy,\n      [TokenType.NUMBER]:\n        /(0x[0-9a-fA-F]+|0b[01]+|(-\\s*)?[0-9]+(\\.[0-9]*)?([eE][-+]?[0-9]+(\\.[0-9]+)?)?)/uy,\n      [TokenType.PARAMETER]: NULL_REGEX, // matches nothing\n      [TokenType.EOF]: NULL_REGEX, // matches nothing\n    };\n\n    this.paramPatterns = this.excludePatternsWithoutRegexes([\n      {\n        // :name placeholders\n        regex: regexFactory.createParameterRegex(\n          cfg.namedParamTypes ?? [],\n          regexFactory.createIdentPattern(cfg.paramChars || cfg.identChars)\n        ),\n        parseKey: v => v.slice(1),\n      },\n      {\n        // :\"name\" placeholders\n        regex: regexFactory.createParameterRegex(\n          cfg.quotedParamTypes ?? [],\n          regexFactory.createQuotePattern(cfg.identTypes)\n        ),\n        parseKey: v =>\n          this.getEscapedPlaceholderKey({ key: v.slice(2, -1), quoteChar: v.slice(-1) }),\n      },\n      {\n        // :1, :2, :3 placeholders\n        regex: regexFactory.createParameterRegex(cfg.numberedParamTypes ?? [], '[0-9]+'),\n        parseKey: v => v.slice(1),\n      },\n      {\n        // ? placeholders\n        regex: cfg.positionalParams ? /(\\?)/uy : undefined,\n        parseKey: v => v.slice(1),\n      },\n    ]);\n  }\n\n  private excludePatternsWithoutRegexes(\n    patterns: { regex?: RegExp; parseKey: (s: string) => string }[]\n  ) {\n    return patterns.filter((p): p is ParamPattern => p.regex !== undefined);\n  }\n\n  /**\n   * Takes a SQL string and breaks it into tokens.\n   * Each token is an object with type and value.\n   *\n   * @param {string} input - The SQL string\n   * @returns {Token[]} output token stream\n   */\n  public tokenize(input: string): Token[] {\n    this.input = input;\n    this.index = 0;\n    const tokens: Token[] = [];\n    let token: Token | undefined;\n\n    // Keep processing the string until end is reached\n    while (this.index < this.input.length) {\n      // grab any preceding whitespace\n      const whitespaceBefore = this.getWhitespace();\n\n      if (this.index < this.input.length) {\n        // Get the next token and the token type\n        token = this.getNextToken(token);\n        if (!token) {\n          throw new Error(`Parse error: Unexpected \"${input.slice(this.index, 100)}\"`);\n        }\n\n        tokens.push({ ...token, whitespaceBefore });\n      }\n    }\n    return this.preprocess(tokens);\n  }\n\n  private getWhitespace(): string {\n    WHITESPACE_REGEX.lastIndex = this.index;\n    const matches = this.input.match(WHITESPACE_REGEX);\n    if (matches) {\n      // Advance current position by matched whitespace length\n      this.index += matches[1].length;\n      return matches[1];\n    } else {\n      return '';\n    }\n  }\n\n  private getNextToken(previousToken?: Token): Token | undefined {\n    return (\n      this.matchToken(TokenType.LINE_COMMENT) ||\n      this.matchToken(TokenType.BLOCK_COMMENT) ||\n      this.matchToken(TokenType.STRING) ||\n      this.matchQuotedIdentToken() ||\n      this.matchToken(TokenType.VARIABLE) ||\n      this.matchToken(TokenType.BLOCK_START) ||\n      this.matchToken(TokenType.BLOCK_END) ||\n      this.matchPlaceholderToken() ||\n      this.matchToken(TokenType.NUMBER) ||\n      this.matchReservedWordToken(previousToken) ||\n      this.matchToken(TokenType.IDENT) ||\n      this.matchToken(TokenType.OPERATOR)\n    );\n  }\n\n  private matchPlaceholderToken(): Token | undefined {\n    for (const { regex, parseKey } of this.paramPatterns) {\n      const token = this.match({\n        regex,\n        type: TokenType.PARAMETER,\n        transform: id,\n      });\n      if (token) {\n        return { ...token, key: parseKey(token.value) };\n      }\n    }\n    return undefined;\n  }\n\n  private getEscapedPlaceholderKey({ key, quoteChar }: { key: string; quoteChar: string }): string {\n    return key.replace(new RegExp(escapeRegExp('\\\\' + quoteChar), 'gu'), quoteChar);\n  }\n\n  private matchQuotedIdentToken(): Token | undefined {\n    return this.match({\n      regex: this.quotedIdentRegex,\n      type: TokenType.IDENT,\n      transform: id,\n    });\n  }\n\n  private matchReservedWordToken(previousToken?: Token): Token | undefined {\n    // A reserved word cannot be preceded by a '.'\n    // this makes it so in \"mytable.from\", \"from\" is not considered a reserved word\n    if (previousToken?.value === '.') {\n      return undefined;\n    }\n\n    // prioritised list of Reserved token types\n    return (\n      this.matchReservedToken(TokenType.RESERVED_CASE_START) ||\n      this.matchReservedToken(TokenType.RESERVED_CASE_END) ||\n      this.matchReservedToken(TokenType.RESERVED_COMMAND) ||\n      this.matchReservedToken(TokenType.RESERVED_BINARY_COMMAND) ||\n      this.matchReservedToken(TokenType.RESERVED_DEPENDENT_CLAUSE) ||\n      this.matchReservedToken(TokenType.RESERVED_LOGICAL_OPERATOR) ||\n      this.matchReservedToken(TokenType.RESERVED_KEYWORD) ||\n      this.matchReservedToken(TokenType.RESERVED_JOIN_CONDITION)\n    );\n  }\n\n  // Helper for matching RESERVED_* tokens which need to be transformed to canonical form\n  private matchReservedToken(tokenType: TokenType): Token | undefined {\n    return this.match({\n      type: tokenType,\n      regex: this.REGEX_MAP[tokenType],\n      transform: toCanonicalKeyword,\n    });\n  }\n\n  // Shorthand for `match` that looks up regex from REGEX_MAP\n  private matchToken(tokenType: TokenType): Token | undefined {\n    return this.match({\n      type: tokenType,\n      regex: this.REGEX_MAP[tokenType],\n      transform: id,\n    });\n  }\n\n  // Attempts to match RegExp at current position in input\n  private match({\n    type,\n    regex,\n    transform,\n  }: {\n    type: TokenType;\n    regex: RegExp;\n    transform: (s: string) => string;\n  }): Token | undefined {\n    regex.lastIndex = this.index;\n    const matches = this.input.match(regex);\n    if (matches) {\n      // Advance current position by matched token length\n      this.index += matches[1].length;\n      return {\n        type,\n        text: matches[1],\n        value: transform(matches[1]),\n      };\n    }\n    return undefined;\n  }\n}\n"],"file":"Tokenizer.js"}
{"version":3,"sources":["../../src/core/Tokenizer.ts"],"names":["WHITESPACE_REGEX","NULL_REGEX","toCanonicalKeyword","text","toUpperCase","Tokenizer","cfg","tokens","preprocess","quotedIdentRegex","regexFactory","createQuoteRegex","identTypes","REGEX_MAP","TokenType","IDENT","createIdentRegex","identChars","STRING","stringTypes","VARIABLE","variableTypes","createVariableRegex","RESERVED_KEYWORD","createReservedWordRegex","reservedKeywords","RESERVED_DEPENDENT_CLAUSE","reservedDependentClauses","RESERVED_LOGICAL_OPERATOR","reservedLogicalOperators","RESERVED_COMMAND","reservedCommands","RESERVED_BINARY_COMMAND","reservedBinaryCommands","RESERVED_JOIN_CONDITION","reservedJoinConditions","OPERATOR","createOperatorRegex","operators","BLOCK_START","createParenRegex","blockStart","BLOCK_END","blockEnd","RESERVED_CASE_START","RESERVED_CASE_END","LINE_COMMENT","createLineCommentRegex","lineCommentTypes","BLOCK_COMMENT","NUMBER","PARAMETER","EOF","paramPatterns","excludePatternsWithoutRegexes","regex","createParameterRegex","namedParamTypes","createIdentPattern","paramChars","parseKey","v","slice","quotedParamTypes","createQuotePattern","getEscapedPlaceholderKey","key","quoteChar","numberedParamTypes","positionalParams","undefined","patterns","filter","p","input","token","length","whitespaceBefore","getWhitespace","substring","getNextToken","Error","push","matches","match","previousToken","matchToken","matchQuotedIdentToken","matchPlaceholderToken","matchReservedWordToken","type","transform","id","value","replace","RegExp","matchReservedToken","tokenType"],"mappings":";;;;;;;;;AAAA;;AAEA;;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEO,IAAMA,gBAAgB,GAAG,yEAAzB;;AACP,IAAMC,UAAU,GAAG,MAAnB,C,CAA2B;;AAE3B,IAAMC,kBAAkB,GAAG,SAArBA,kBAAqB,CAACC,IAAD;AAAA,SAAkB,+BAAmBA,IAAI,CAACC,WAAL,EAAnB,CAAlB;AAAA,CAA3B;AAEA;;;AAuDA;IACqBC,S;AAOnB,qBAAYC,GAAZ,EAAmC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;;AAAA;;AAAA;;AAAA,wCAFd,UAACC,MAAD;AAAA,aAAqBA,MAArB;AAAA,KAEc;;AACjC,QAAID,GAAG,CAACE,UAAR,EAAoB;AAClB,WAAKA,UAAL,GAAkBF,GAAG,CAACE,UAAtB;AACD;;AAED,SAAKC,gBAAL,GAAwBC,YAAY,CAACC,gBAAb,CAA8BL,GAAG,CAACM,UAAlC,CAAxB;AAEA,SAAKC,SAAL,2DACGC,iBAAUC,KADb,EACqBL,YAAY,CAACM,gBAAb,CAA8BV,GAAG,CAACW,UAAlC,CADrB,oCAEGH,iBAAUI,MAFb,EAEsBR,YAAY,CAACC,gBAAb,CAA8BL,GAAG,CAACa,WAAlC,CAFtB,oCAGGL,iBAAUM,QAHb,EAGwBd,GAAG,CAACe,aAAJ,GAClBX,YAAY,CAACY,mBAAb,CAAiChB,GAAG,CAACe,aAArC,CADkB,GAElBpB,UALN,oCAMGa,iBAAUS,gBANb,EAMgCb,YAAY,CAACc,uBAAb,CAC5BlB,GAAG,CAACmB,gBADwB,EAE5BnB,GAAG,CAACW,UAFwB,CANhC,oCAUGH,iBAAUY,yBAVb,EAUyChB,YAAY,CAACc,uBAAb,0BACrClB,GAAG,CAACqB,wBADiC,yEACL,EADK,EAErCrB,GAAG,CAACW,UAFiC,CAVzC,oCAcGH,iBAAUc,yBAdb,EAcyClB,YAAY,CAACc,uBAAb,0BACrClB,GAAG,CAACuB,wBADiC,yEACL,CAAC,KAAD,EAAQ,IAAR,CADK,EAErCvB,GAAG,CAACW,UAFiC,CAdzC,oCAkBGH,iBAAUgB,gBAlBb,EAkBgCpB,YAAY,CAACc,uBAAb,CAC5BlB,GAAG,CAACyB,gBADwB,EAE5BzB,GAAG,CAACW,UAFwB,CAlBhC,oCAsBGH,iBAAUkB,uBAtBb,EAsBuCtB,YAAY,CAACc,uBAAb,CACnClB,GAAG,CAAC2B,sBAD+B,EAEnC3B,GAAG,CAACW,UAF+B,CAtBvC,oCA0BGH,iBAAUoB,uBA1Bb,EA0BuCxB,YAAY,CAACc,uBAAb,0BACnClB,GAAG,CAAC6B,sBAD+B,yEACL,CAAC,IAAD,EAAO,OAAP,CADK,EAEnC7B,GAAG,CAACW,UAF+B,CA1BvC,oCA8BGH,iBAAUsB,QA9Bb,EA8BwB1B,YAAY,CAAC2B,mBAAb,CAAiC,wBAAjC,GACpB,IADoB,EAEpB,IAFoB,EAGpB,IAHoB,EAIpB,IAJoB,8CAKhB/B,GAAG,CAACgC,SALY,2DAKC,EALD,GA9BxB,oCAqCGxB,iBAAUyB,WArCb,EAqC2B7B,YAAY,CAAC8B,gBAAb,oBAA8BlC,GAAG,CAACmC,UAAlC,6DAAgD,CAAC,GAAD,CAAhD,CArC3B,oCAsCG3B,iBAAU4B,SAtCb,EAsCyBhC,YAAY,CAAC8B,gBAAb,kBAA8BlC,GAAG,CAACqC,QAAlC,yDAA8C,CAAC,GAAD,CAA9C,CAtCzB,oCAuCG7B,iBAAU8B,mBAvCb,EAuCmC,oBAvCnC,oCAwCG9B,iBAAU+B,iBAxCb,EAwCiC,WAxCjC,oCAyCG/B,iBAAUgC,YAzCb,EAyC4BpC,YAAY,CAACqC,sBAAb,0BAAoCzC,GAAG,CAAC0C,gBAAxC,yEAA4D,CAAC,IAAD,CAA5D,CAzC5B,oCA0CGlC,iBAAUmC,aA1Cb,EA0C6B,qCA1C7B,oCA2CGnC,iBAAUoC,MA3Cb,EA4CI,yJA5CJ,oCA6CGpC,iBAAUqC,SA7Cb,EA6CyBlD,UA7CzB,oCA8CGa,iBAAUsC,GA9Cb,EA8CmBnD,UA9CnB;AAiDA,SAAKoD,aAAL,GAAqB,KAAKC,6BAAL,CAAmC,CACtD;AACE;AACAC,MAAAA,KAAK,EAAE7C,YAAY,CAAC8C,oBAAb,yBACLlD,GAAG,CAACmD,eADC,uEACkB,EADlB,EAEL/C,YAAY,CAACgD,kBAAb,CAAgCpD,GAAG,CAACqD,UAAJ,IAAkBrD,GAAG,CAACW,UAAtD,CAFK,CAFT;AAME2C,MAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,eAAIA,CAAC,CAACC,KAAF,CAAQ,CAAR,CAAJ;AAAA;AANb,KADsD,EAStD;AACE;AACAP,MAAAA,KAAK,EAAE7C,YAAY,CAAC8C,oBAAb,0BACLlD,GAAG,CAACyD,gBADC,yEACmB,EADnB,EAELrD,YAAY,CAACsD,kBAAb,CAAgC1D,GAAG,CAACM,UAApC,CAFK,CAFT;AAMEgD,MAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,eACT,KAAI,CAACI,wBAAL,CAA8B;AAAEC,UAAAA,GAAG,EAAEL,CAAC,CAACC,KAAF,CAAQ,CAAR,EAAW,CAAC,CAAZ,CAAP;AAAuBK,UAAAA,SAAS,EAAEN,CAAC,CAACC,KAAF,CAAQ,CAAC,CAAT;AAAlC,SAA9B,CADS;AAAA;AANb,KATsD,EAkBtD;AACE;AACAP,MAAAA,KAAK,EAAE7C,YAAY,CAAC8C,oBAAb,0BAAkClD,GAAG,CAAC8D,kBAAtC,yEAA4D,EAA5D,EAAgE,QAAhE,CAFT;AAGER,MAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,eAAIA,CAAC,CAACC,KAAF,CAAQ,CAAR,CAAJ;AAAA;AAHb,KAlBsD,EAuBtD;AACE;AACAP,MAAAA,KAAK,EAAEjD,GAAG,CAAC+D,gBAAJ,GAAuB,OAAvB,GAAiCC,SAF1C;AAGEV,MAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,eAAIA,CAAC,CAACC,KAAF,CAAQ,CAAR,CAAJ;AAAA;AAHb,KAvBsD,CAAnC,CAArB;AA6BD;;;;WAED,uCACES,QADF,EAEE;AACA,aAAOA,QAAQ,CAACC,MAAT,CAAgB,UAACC,CAAD;AAAA,eAA0BA,CAAC,CAAClB,KAAF,KAAYe,SAAtC;AAAA,OAAhB,CAAP;AACD;AAED;AACF;AACA;AACA;AACA;AACA;AACA;;;;WACE,kBAAgBI,KAAhB,EAAwC;AACtC,UAAMnE,MAAe,GAAG,EAAxB;AACA,UAAIoE,KAAJ,CAFsC,CAItC;;AACA,aAAOD,KAAK,CAACE,MAAb,EAAqB;AACnB;AACA,YAAMC,gBAAgB,GAAG,KAAKC,aAAL,CAAmBJ,KAAnB,CAAzB;AACAA,QAAAA,KAAK,GAAGA,KAAK,CAACK,SAAN,CAAgBF,gBAAgB,CAACD,MAAjC,CAAR;;AAEA,YAAIF,KAAK,CAACE,MAAV,EAAkB;AAChB;AACAD,UAAAA,KAAK,GAAG,KAAKK,YAAL,CAAkBN,KAAlB,EAAyBC,KAAzB,CAAR;;AACA,cAAI,CAACA,KAAL,EAAY;AACV,kBAAM,IAAIM,KAAJ,qCAAsCP,KAAK,CAACZ,KAAN,CAAY,CAAZ,EAAe,GAAf,CAAtC,QAAN;AACD,WALe,CAMhB;;;AACAY,UAAAA,KAAK,GAAGA,KAAK,CAACK,SAAN,CAAgBJ,KAAK,CAACxE,IAAN,CAAWyE,MAA3B,CAAR;AAEArE,UAAAA,MAAM,CAAC2E,IAAP,iCAAiBP,KAAjB;AAAwBE,YAAAA,gBAAgB,EAAhBA;AAAxB;AACD;AACF;;AACD,aAAO,KAAKrE,UAAL,CAAgBD,MAAhB,CAAP;AACD;AAED;;;;WACA,uBAAsBmE,KAAtB,EAA6C;AAC3C,UAAMS,OAAO,GAAGT,KAAK,CAACU,KAAN,CAAYpF,gBAAZ,CAAhB;AACA,aAAOmF,OAAO,GAAGA,OAAO,CAAC,CAAD,CAAV,GAAgB,EAA9B;AACD;AAED;;;;WACA,sBAAqBT,KAArB,EAAoCW,aAApC,EAA8E;AAC5E,aACE,KAAKC,UAAL,CAAgBxE,iBAAUgC,YAA1B,EAAwC4B,KAAxC,KACA,KAAKY,UAAL,CAAgBxE,iBAAUmC,aAA1B,EAAyCyB,KAAzC,CADA,IAEA,KAAKY,UAAL,CAAgBxE,iBAAUI,MAA1B,EAAkCwD,KAAlC,CAFA,IAGA,KAAKa,qBAAL,CAA2Bb,KAA3B,CAHA,IAIA,KAAKY,UAAL,CAAgBxE,iBAAUM,QAA1B,EAAoCsD,KAApC,CAJA,IAKA,KAAKY,UAAL,CAAgBxE,iBAAUyB,WAA1B,EAAuCmC,KAAvC,CALA,IAMA,KAAKY,UAAL,CAAgBxE,iBAAU4B,SAA1B,EAAqCgC,KAArC,CANA,IAOA,KAAKc,qBAAL,CAA2Bd,KAA3B,CAPA,IAQA,KAAKY,UAAL,CAAgBxE,iBAAUoC,MAA1B,EAAkCwB,KAAlC,CARA,IASA,KAAKe,sBAAL,CAA4Bf,KAA5B,EAAmCW,aAAnC,CATA,IAUA,KAAKC,UAAL,CAAgBxE,iBAAUC,KAA1B,EAAiC2D,KAAjC,CAVA,IAWA,KAAKY,UAAL,CAAgBxE,iBAAUsB,QAA1B,EAAoCsC,KAApC,CAZF;AAcD;AAED;AACF;AACA;AACA;;;;WACE,+BAA8BA,KAA9B,EAAgE;AAAA,iDAC5B,KAAKrB,aADuB;AAAA;;AAAA;AAC9D,4DAAsD;AAAA;AAAA,cAAzCE,KAAyC,eAAzCA,KAAyC;AAAA,cAAlCK,QAAkC,eAAlCA,QAAkC;AACpD,cAAMe,KAAK,GAAG,KAAKS,KAAL,CAAW;AACvBV,YAAAA,KAAK,EAALA,KADuB;AAEvBnB,YAAAA,KAAK,EAALA,KAFuB;AAGvBmC,YAAAA,IAAI,EAAE5E,iBAAUqC,SAHO;AAIvBwC,YAAAA,SAAS,EAAEC;AAJY,WAAX,CAAd;;AAMA,cAAIjB,KAAJ,EAAW;AACT,mDAAYA,KAAZ;AAAmBT,cAAAA,GAAG,EAAEN,QAAQ,CAACe,KAAK,CAACkB,KAAP;AAAhC;AACD;AACF;AAX6D;AAAA;AAAA;AAAA;AAAA;;AAY9D,aAAOvB,SAAP;AACD;;;WAED,wCAAiG;AAAA,UAA9DJ,GAA8D,QAA9DA,GAA8D;AAAA,UAAzDC,SAAyD,QAAzDA,SAAyD;AAC/F,aAAOD,GAAG,CAAC4B,OAAJ,CAAY,IAAIC,MAAJ,CAAW,yBAAa,OAAO5B,SAApB,CAAX,EAA2C,IAA3C,CAAZ,EAA8DA,SAA9D,CAAP;AACD;;;WAED,+BAA8BO,KAA9B,EAAgE;AAC9D,aAAO,KAAKU,KAAL,CAAW;AAChBV,QAAAA,KAAK,EAALA,KADgB;AAEhBnB,QAAAA,KAAK,EAAE,KAAK9C,gBAFI;AAGhBiF,QAAAA,IAAI,EAAE5E,iBAAUC,KAHA;AAIhB4E,QAAAA,SAAS,EAAEC;AAJK,OAAX,CAAP;AAMD;AAED;AACF;AACA;AACA;;;;WACE,gCAA+BlB,KAA/B,EAA8CW,aAA9C,EAAwF;AACtF;AACA;AACA,UAAI,CAAAA,aAAa,SAAb,IAAAA,aAAa,WAAb,YAAAA,aAAa,CAAEQ,KAAf,MAAyB,GAA7B,EAAkC;AAChC,eAAOvB,SAAP;AACD,OALqF,CAOtF;;;AACA,aACE,KAAK0B,kBAAL,CAAwBlF,iBAAU8B,mBAAlC,EAAuD8B,KAAvD,KACA,KAAKsB,kBAAL,CAAwBlF,iBAAU+B,iBAAlC,EAAqD6B,KAArD,CADA,IAEA,KAAKsB,kBAAL,CAAwBlF,iBAAUgB,gBAAlC,EAAoD4C,KAApD,CAFA,IAGA,KAAKsB,kBAAL,CAAwBlF,iBAAUkB,uBAAlC,EAA2D0C,KAA3D,CAHA,IAIA,KAAKsB,kBAAL,CAAwBlF,iBAAUY,yBAAlC,EAA6DgD,KAA7D,CAJA,IAKA,KAAKsB,kBAAL,CAAwBlF,iBAAUc,yBAAlC,EAA6D8C,KAA7D,CALA,IAMA,KAAKsB,kBAAL,CAAwBlF,iBAAUS,gBAAlC,EAAoDmD,KAApD,CANA,IAOA,KAAKsB,kBAAL,CAAwBlF,iBAAUoB,uBAAlC,EAA2DwC,KAA3D,CARF;AAUD,K,CAED;;;;WACA,4BAA2BuB,SAA3B,EAAiDvB,KAAjD,EAAmF;AACjF,aAAO,KAAKU,KAAL,CAAW;AAChBV,QAAAA,KAAK,EAALA,KADgB;AAEhBgB,QAAAA,IAAI,EAAEO,SAFU;AAGhB1C,QAAAA,KAAK,EAAE,KAAK1C,SAAL,CAAeoF,SAAf,CAHS;AAIhBN,QAAAA,SAAS,EAAEzF;AAJK,OAAX,CAAP;AAMD,K,CAED;;;;WACA,oBAAmB+F,SAAnB,EAAyCvB,KAAzC,EAA2E;AACzE,aAAO,KAAKU,KAAL,CAAW;AAChBV,QAAAA,KAAK,EAALA,KADgB;AAEhBgB,QAAAA,IAAI,EAAEO,SAFU;AAGhB1C,QAAAA,KAAK,EAAE,KAAK1C,SAAL,CAAeoF,SAAf,CAHS;AAIhBN,QAAAA,SAAS,EAAEC;AAJK,OAAX,CAAP;AAMD;AAED;AACF;AACA;AACA;AACA;AACA;AACA;;;;WACE,sBAUsB;AAAA,UATpBlB,KASoB,SATpBA,KASoB;AAAA,UARpBgB,IAQoB,SARpBA,IAQoB;AAAA,UAPpBnC,KAOoB,SAPpBA,KAOoB;AAAA,UANpBoC,SAMoB,SANpBA,SAMoB;AACpB,UAAMR,OAAO,GAAGT,KAAK,CAACU,KAAN,CAAY7B,KAAZ,CAAhB;;AACA,UAAI4B,OAAJ,EAAa;AACX,eAAO;AACLO,UAAAA,IAAI,EAAJA,IADK;AAELvF,UAAAA,IAAI,EAAEgF,OAAO,CAAC,CAAD,CAFR;AAGLU,UAAAA,KAAK,EAAEF,SAAS,CAACR,OAAO,CAAC,CAAD,CAAR;AAHX,SAAP;AAKD;;AACD,aAAOb,SAAP;AACD","sourcesContent":["import { equalizeWhitespace, escapeRegExp, id } from 'src/utils';\n\nimport * as regexFactory from './regexFactory';\nimport { type Token, TokenType } from './token';\n\nexport const WHITESPACE_REGEX = /^(\\s+)/u;\nconst NULL_REGEX = /(?!)/; // zero-width negative lookahead, matches nothing\n\nconst toCanonicalKeyword = (text: string) => equalizeWhitespace(text.toUpperCase());\n\n/** Struct that defines how a SQL language can be broken into tokens */\ninterface TokenizerOptions {\n  // Main clauses that start new block, like: SELECT, FROM, WHERE, ORDER BY\n  reservedCommands: string[];\n  // Logical operator keywords, defaults to: [AND, OR]\n  reservedLogicalOperators?: string[];\n  // Keywords in CASE expressions that begin new line, like: WHEN, ELSE\n  reservedDependentClauses: string[];\n  // Keywords that create newline but no indentaion of their body.\n  // These contain set operations like UNION and various joins like LEFT OUTER JOIN\n  reservedBinaryCommands: string[];\n  // keywords used for JOIN conditions, defaults to: [ON, USING]\n  reservedJoinConditions?: string[];\n  // all other reserved words (not included to any of the above lists)\n  reservedKeywords: string[];\n  // Types of quotes to use for strings\n  stringTypes: regexFactory.QuoteType[];\n  // Types of quotes to use for quoted identifiers\n  identTypes: regexFactory.QuoteType[];\n  // Types of quotes to use for variables\n  variableTypes?: regexFactory.VariableType[];\n  // Open-parenthesis characters, like: (, [, {\n  blockStart?: string[];\n  // Close-parenthesis characters, like: ), ], }\n  blockEnd?: string[];\n  // True to allow for positional \"?\" parameter placeholders\n  positionalParams?: boolean;\n  // Prefixes for numbered parameter placeholders to support, e.g. :1, :2, :3\n  numberedParamTypes?: ('?' | ':' | '$')[];\n  // Prefixes for named parameter placeholders to support, e.g. :name\n  namedParamTypes?: (':' | '@' | '$')[];\n  // Prefixes for quoted parameter placeholders to support, e.g. :\"name\"\n  // The type of quotes will depend on `identifierTypes` option.\n  quotedParamTypes?: (':' | '@' | '$')[];\n  // Line comment types to support, defaults to --\n  lineCommentTypes?: string[];\n  // Additional characters to support in identifiers\n  identChars?: regexFactory.IdentChars;\n  // Additional characters to support in named parameters\n  // Use this when parameters allow different characters from identifiers\n  // Defaults to `identChars`.\n  paramChars?: regexFactory.IdentChars;\n  // Additional multi-character operators to support, in addition to <=, >=, <>, !=\n  operators?: string[];\n  // Allows custom modifications on the token array.\n  // Called after the whole input string has been split into tokens.\n  // The result of this will be the output of the tokenizer.\n  preprocess?: (tokens: Token[]) => Token[];\n}\n\ninterface ParamPattern {\n  regex: RegExp;\n  parseKey: (s: string) => string;\n}\n\n/** Converts SQL language string into a token stream */\nexport default class Tokenizer {\n  private REGEX_MAP: Record<TokenType, RegExp>;\n  private quotedIdentRegex: RegExp;\n  private paramPatterns: ParamPattern[];\n\n  private preprocess = (tokens: Token[]) => tokens;\n\n  constructor(cfg: TokenizerOptions) {\n    if (cfg.preprocess) {\n      this.preprocess = cfg.preprocess;\n    }\n\n    this.quotedIdentRegex = regexFactory.createQuoteRegex(cfg.identTypes);\n\n    this.REGEX_MAP = {\n      [TokenType.IDENT]: regexFactory.createIdentRegex(cfg.identChars),\n      [TokenType.STRING]: regexFactory.createQuoteRegex(cfg.stringTypes),\n      [TokenType.VARIABLE]: cfg.variableTypes\n        ? regexFactory.createVariableRegex(cfg.variableTypes)\n        : NULL_REGEX,\n      [TokenType.RESERVED_KEYWORD]: regexFactory.createReservedWordRegex(\n        cfg.reservedKeywords,\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_DEPENDENT_CLAUSE]: regexFactory.createReservedWordRegex(\n        cfg.reservedDependentClauses ?? [],\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_LOGICAL_OPERATOR]: regexFactory.createReservedWordRegex(\n        cfg.reservedLogicalOperators ?? ['AND', 'OR'],\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_COMMAND]: regexFactory.createReservedWordRegex(\n        cfg.reservedCommands,\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_BINARY_COMMAND]: regexFactory.createReservedWordRegex(\n        cfg.reservedBinaryCommands,\n        cfg.identChars\n      ),\n      [TokenType.RESERVED_JOIN_CONDITION]: regexFactory.createReservedWordRegex(\n        cfg.reservedJoinConditions ?? ['ON', 'USING'],\n        cfg.identChars\n      ),\n      [TokenType.OPERATOR]: regexFactory.createOperatorRegex('+-/*%&|^><=.,;[]{}`:$@', [\n        '<>',\n        '<=',\n        '>=',\n        '!=',\n        ...(cfg.operators ?? []),\n      ]),\n      [TokenType.BLOCK_START]: regexFactory.createParenRegex(cfg.blockStart ?? ['(']),\n      [TokenType.BLOCK_END]: regexFactory.createParenRegex(cfg.blockEnd ?? [')']),\n      [TokenType.RESERVED_CASE_START]: /^(CASE)\\b/iu,\n      [TokenType.RESERVED_CASE_END]: /^(END)\\b/iu,\n      [TokenType.LINE_COMMENT]: regexFactory.createLineCommentRegex(cfg.lineCommentTypes ?? ['--']),\n      [TokenType.BLOCK_COMMENT]: /^(\\/\\*[^]*?(?:\\*\\/|$))/u,\n      [TokenType.NUMBER]:\n        /^(0x[0-9a-fA-F]+|0b[01]+|(-\\s*)?[0-9]+(\\.[0-9]*)?([eE][-+]?[0-9]+(\\.[0-9]+)?)?)/u,\n      [TokenType.PARAMETER]: NULL_REGEX, // matches nothing\n      [TokenType.EOF]: NULL_REGEX, // matches nothing\n    };\n\n    this.paramPatterns = this.excludePatternsWithoutRegexes([\n      {\n        // :name placeholders\n        regex: regexFactory.createParameterRegex(\n          cfg.namedParamTypes ?? [],\n          regexFactory.createIdentPattern(cfg.paramChars || cfg.identChars)\n        ),\n        parseKey: v => v.slice(1),\n      },\n      {\n        // :\"name\" placeholders\n        regex: regexFactory.createParameterRegex(\n          cfg.quotedParamTypes ?? [],\n          regexFactory.createQuotePattern(cfg.identTypes)\n        ),\n        parseKey: v =>\n          this.getEscapedPlaceholderKey({ key: v.slice(2, -1), quoteChar: v.slice(-1) }),\n      },\n      {\n        // :1, :2, :3 placeholders\n        regex: regexFactory.createParameterRegex(cfg.numberedParamTypes ?? [], '[0-9]+'),\n        parseKey: v => v.slice(1),\n      },\n      {\n        // ? placeholders\n        regex: cfg.positionalParams ? /^(\\?)/ : undefined,\n        parseKey: v => v.slice(1),\n      },\n    ]);\n  }\n\n  private excludePatternsWithoutRegexes(\n    patterns: { regex?: RegExp; parseKey: (s: string) => string }[]\n  ) {\n    return patterns.filter((p): p is ParamPattern => p.regex !== undefined);\n  }\n\n  /**\n   * Takes a SQL string and breaks it into tokens.\n   * Each token is an object with type and value.\n   *\n   * @param {string} input - The SQL string\n   * @returns {Token[]} output token stream\n   */\n  public tokenize(input: string): Token[] {\n    const tokens: Token[] = [];\n    let token: Token | undefined;\n\n    // Keep processing the string until it is empty\n    while (input.length) {\n      // grab any preceding whitespace\n      const whitespaceBefore = this.getWhitespace(input);\n      input = input.substring(whitespaceBefore.length);\n\n      if (input.length) {\n        // Get the next token and the token type\n        token = this.getNextToken(input, token);\n        if (!token) {\n          throw new Error(`Parse error: Unexpected \"${input.slice(0, 100)}\"`);\n        }\n        // Advance the string\n        input = input.substring(token.text.length);\n\n        tokens.push({ ...token, whitespaceBefore });\n      }\n    }\n    return this.preprocess(tokens);\n  }\n\n  /** Matches preceding whitespace if present */\n  private getWhitespace(input: string): string {\n    const matches = input.match(WHITESPACE_REGEX);\n    return matches ? matches[1] : '';\n  }\n\n  /** Attempts to match next token from input string, tests RegExp patterns in decreasing priority */\n  private getNextToken(input: string, previousToken?: Token): Token | undefined {\n    return (\n      this.matchToken(TokenType.LINE_COMMENT, input) ||\n      this.matchToken(TokenType.BLOCK_COMMENT, input) ||\n      this.matchToken(TokenType.STRING, input) ||\n      this.matchQuotedIdentToken(input) ||\n      this.matchToken(TokenType.VARIABLE, input) ||\n      this.matchToken(TokenType.BLOCK_START, input) ||\n      this.matchToken(TokenType.BLOCK_END, input) ||\n      this.matchPlaceholderToken(input) ||\n      this.matchToken(TokenType.NUMBER, input) ||\n      this.matchReservedWordToken(input, previousToken) ||\n      this.matchToken(TokenType.IDENT, input) ||\n      this.matchToken(TokenType.OPERATOR, input)\n    );\n  }\n\n  /**\n   * Attempts to match a placeholder token pattern\n   * @return {Token | undefined} - The placeholder token if found, otherwise undefined\n   */\n  private matchPlaceholderToken(input: string): Token | undefined {\n    for (const { regex, parseKey } of this.paramPatterns) {\n      const token = this.match({\n        input,\n        regex,\n        type: TokenType.PARAMETER,\n        transform: id,\n      });\n      if (token) {\n        return { ...token, key: parseKey(token.value) };\n      }\n    }\n    return undefined;\n  }\n\n  private getEscapedPlaceholderKey({ key, quoteChar }: { key: string; quoteChar: string }): string {\n    return key.replace(new RegExp(escapeRegExp('\\\\' + quoteChar), 'gu'), quoteChar);\n  }\n\n  private matchQuotedIdentToken(input: string): Token | undefined {\n    return this.match({\n      input,\n      regex: this.quotedIdentRegex,\n      type: TokenType.IDENT,\n      transform: id,\n    });\n  }\n\n  /**\n   * Attempts to match a Reserved word token pattern, avoiding edge cases of Reserved words within string tokens\n   * @return {Token | undefined} - The Reserved word token if found, otherwise undefined\n   */\n  private matchReservedWordToken(input: string, previousToken?: Token): Token | undefined {\n    // A reserved word cannot be preceded by a '.'\n    // this makes it so in \"mytable.from\", \"from\" is not considered a reserved word\n    if (previousToken?.value === '.') {\n      return undefined;\n    }\n\n    // prioritised list of Reserved token types\n    return (\n      this.matchReservedToken(TokenType.RESERVED_CASE_START, input) ||\n      this.matchReservedToken(TokenType.RESERVED_CASE_END, input) ||\n      this.matchReservedToken(TokenType.RESERVED_COMMAND, input) ||\n      this.matchReservedToken(TokenType.RESERVED_BINARY_COMMAND, input) ||\n      this.matchReservedToken(TokenType.RESERVED_DEPENDENT_CLAUSE, input) ||\n      this.matchReservedToken(TokenType.RESERVED_LOGICAL_OPERATOR, input) ||\n      this.matchReservedToken(TokenType.RESERVED_KEYWORD, input) ||\n      this.matchReservedToken(TokenType.RESERVED_JOIN_CONDITION, input)\n    );\n  }\n\n  // Helper for matching RESERVED_* tokens which need to be transformed to canonical form\n  private matchReservedToken(tokenType: TokenType, input: string): Token | undefined {\n    return this.match({\n      input,\n      type: tokenType,\n      regex: this.REGEX_MAP[tokenType],\n      transform: toCanonicalKeyword,\n    });\n  }\n\n  // Shorthand for `match` that looks up regex from REGEX_MAP\n  private matchToken(tokenType: TokenType, input: string): Token | undefined {\n    return this.match({\n      input,\n      type: tokenType,\n      regex: this.REGEX_MAP[tokenType],\n      transform: id,\n    });\n  }\n\n  /**\n   * Attempts to match RegExp from head of input, returning undefined if not found\n   * @param {string} _.input - The string to match\n   * @param {TokenType} _.type - The type of token to match against\n   * @param {RegExp} _.regex - The regex to match\n   * @return {Token | undefined} - The matched token if found, otherwise undefined\n   */\n  private match({\n    input,\n    type,\n    regex,\n    transform,\n  }: {\n    input: string;\n    type: TokenType;\n    regex: RegExp;\n    transform: (s: string) => string;\n  }): Token | undefined {\n    const matches = input.match(regex);\n    if (matches) {\n      return {\n        type,\n        text: matches[1],\n        value: transform(matches[1]),\n      };\n    }\n    return undefined;\n  }\n}\n"],"file":"Tokenizer.js"}